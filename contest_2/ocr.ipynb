{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import shuffle, seed\n",
    "from typing import Union, List, Tuple, Dict\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchmetrics import CharErrorRate\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    TRAIN_IMAGES = \"data/train/train\"\n",
    "    TEST_IMAGES = \"data/test/test\"\n",
    "    TRAIN_LABELS = \"data/train_labels.csv\"\n",
    "\n",
    "    INPUT_SIZE = [100, 300]\n",
    "    IMAGENET_MEAN = [0.485, 0.456, 0.406] \n",
    "    IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # torch.device(\"cpu\") # \n",
    "\n",
    "    SEED = 42\n",
    "    BATCH_SIZE = 4\n",
    "    BLANK_LABEL = 0\n",
    "\n",
    "\n",
    "seed(config.SEED)\n",
    "np.random.seed(config.SEED)\n",
    "torch.manual_seed(config.SEED)\n",
    "torch.cuda.manual_seed(config.SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelConverter:\n",
    "    def __init__(self, chars: str):\n",
    "        self.chars = chars\n",
    "        self.chars_dimension = len(chars)\n",
    "        self.char2idx = {\n",
    "            char.encode('utf-8'): idx for idx, char in zip(range(1, self.chars_dimension + 1), chars)\n",
    "        }\n",
    "        self.idx2char = {idx: char for char, idx in self.char2idx.items()}\n",
    "\n",
    "    def encode(\n",
    "        self, labels: Union[str, List, Tuple]\n",
    "    ) -> Tuple[torch.IntTensor, torch.IntTensor]:\n",
    "        if isinstance(labels, str):\n",
    "            labels = [labels]\n",
    "\n",
    "        length = [len(label) for label in labels]\n",
    "        labels = \"\".join(labels)\n",
    "        labels = [self.char2idx[char.encode('utf-8')] for char in labels]\n",
    "        return torch.IntTensor(labels), torch.IntTensor(length)\n",
    "\n",
    "    def decode(self, logit: torch.Tensor) -> str:\n",
    "        index = logit.cpu().argmax(2)\n",
    "        index = index.squeeze(1).numpy()\n",
    "        chars = [self.idx2char[idx].decode('utf-8') if idx != 0 else \"/%/\" for idx in index]\n",
    "        chars = \"\".join(chars)\n",
    "        chars = chars.split(\"/%/\")\n",
    "\n",
    "        label = []\n",
    "        for char in chars:\n",
    "            if len(char) != 0:\n",
    "                label.append(char[0])\n",
    "\n",
    "        label = \"\".join(label)\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(config.TRAIN_LABELS)\n",
    "chars = \"\".join(set(\"\".join([str(i) for i in target.Expected.tolist()])))\n",
    "\n",
    "label_converter = LabelConverter(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCR_Dataset_Train(Dataset):\n",
    "    def __init__(self, path_images: str, path_labels: str, train: bool = True):\n",
    "        self.path_images = path_images\n",
    "        self.path_labels = path_labels\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        files = os.listdir(path_images)\n",
    "        shuffle(files)\n",
    "\n",
    "        target = pd.read_csv(self.path_labels)\n",
    "        for image in files:\n",
    "            label = str(target[target[\"Id\"] == image][\"Expected\"].values[0])\n",
    "            self.images.append(os.path.join(path_images, image))\n",
    "            self.labels.append(label)\n",
    "\n",
    "        if train:  # 80%\n",
    "            self.images = self.images[: int(0.8 * len(self.images))]\n",
    "            self.labels = self.labels[: int(0.8 * len(self.labels))]\n",
    "\n",
    "        else:  # 20%\n",
    "            self.images = self.images[int(0.8 * len(self.images)) :]\n",
    "            self.labels = self.labels[int(0.8 * len(self.labels)) :]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path_img, label = self.images[index], self.labels[index]\n",
    "        image = Image.open(path_img)\n",
    "\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                lambda image: image.convert(\"RGB\"),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Resize((config.INPUT_SIZE[0], config.INPUT_SIZE[1])), \n",
    "                transforms.Normalize(config.IMAGENET_MEAN, config.IMAGENET_STD)\n",
    "            ]\n",
    "        )\n",
    "        img = transform(image)\n",
    "\n",
    "        return img, label, path_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = OCR_Dataset_Train(config.TRAIN_IMAGES, config.TRAIN_LABELS, train=True)\n",
    "test_data = OCR_Dataset_Train(config.TRAIN_IMAGES, config.TRAIN_LABELS, train=False)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=config.BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220800, 55200)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_size, output_len):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "\n",
    "        h, w = input_size\n",
    "        resnet = getattr(models, 'resnet18')('ResNet18_Weights.DEFAULT')\n",
    "        self.cnn = nn.Sequential(*list(resnet.children())[:-2])\n",
    "\n",
    "        for name, param in self.cnn.named_parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        with torch.no_grad():\n",
    "            latent_space_width = self.cnn(torch.randn(size=(10, 3, h, w))).shape[3]\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, latent_space_width))  \n",
    "        self.proj = nn.Conv2d(latent_space_width, output_len, kernel_size=1)\n",
    "        self.num_output_features = self.cnn[-1][-1].bn2.num_features    \n",
    "   \n",
    "    def forward(self, x):\n",
    "        features = self.cnn(x)\n",
    "        features = self.pool(features)\n",
    "        features = features.permute(0, 3, 2, 1).contiguous()\n",
    "        features = self.proj(features)\n",
    "        features = features.permute(0, 2, 3, 1).contiguous()\n",
    "        return features\n",
    "    \n",
    "\n",
    "class SequencePredictor(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_size, \n",
    "        hidden_size, \n",
    "        num_layers, \n",
    "        num_classes, \n",
    "        dropout=0.3, \n",
    "        bidirectional=True\n",
    "        ):\n",
    "        super(SequencePredictor, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes        \n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            bidirectional=bidirectional\n",
    "            )\n",
    "        fc_in = hidden_size if not bidirectional else 2 * hidden_size\n",
    "        self.fc = nn.Linear(in_features=fc_in, out_features=num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.squeeze(1)\n",
    "        x = x.permute(2, 0, 1)\n",
    "        batch_size = x.size(1)\n",
    "        num_directions = 2 if self.rnn.bidirectional else 1\n",
    "        h_0 = torch.zeros(self.rnn.num_layers * num_directions, batch_size, self.rnn.hidden_size)\n",
    "        h_0 = h_0.to(x.device)\n",
    "        x, _ = self.rnn(x, h_0)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class OCR_Model(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        cnn_input_size=config.INPUT_SIZE, \n",
    "        cnn_output_len=256, \n",
    "        num_classes=label_converter.chars_dimension,\n",
    "        rnn_hidden_size=128, \n",
    "        rnn_num_layers=2, \n",
    "        rnn_dropout=0.3, \n",
    "        rnn_bidirectional=True\n",
    "        ):\n",
    "        super(OCR_Model, self).__init__()\n",
    "\n",
    "        self.features_extractor = FeatureExtractor(input_size=cnn_input_size, output_len=cnn_output_len)\n",
    "        self.sequence_predictor = SequencePredictor(\n",
    "            input_size=self.features_extractor.num_output_features,\n",
    "            hidden_size=rnn_hidden_size, \n",
    "            num_layers=rnn_num_layers,\n",
    "            num_classes=num_classes, \n",
    "            dropout=rnn_dropout,\n",
    "            bidirectional=rnn_bidirectional\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features_extractor(x)\n",
    "        sequence = self.sequence_predictor(features)\n",
    "        return sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OCR_Model().to(device=config.DEVICE)\n",
    "criterion = nn.CTCLoss(blank=config.BLANK_LABEL, zero_infinity=True)\n",
    "\n",
    "lr = 0.002\n",
    "weight_decay = 1e-5\n",
    "momentum = 0.9\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, nesterov=True, weight_decay=weight_decay, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(epoch: int, train_loss: List, test_loss: List):\n",
    "    display.clear_output(True)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    ax[0].plot(train_loss)\n",
    "    ax[1].plot(test_loss)\n",
    "\n",
    "    train_title = f\"Epoch:{epoch} // Train Loss:{np.mean(train_loss[-100:]):.5f}\"\n",
    "    test_title = f\"Epoch:{epoch} // Test Loss:{np.mean(test_loss[-100:]):.5f}\"\n",
    "    ax[0].set_title(train_title)\n",
    "    ax[1].set_title(test_title)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recognition:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: OCR_Model,\n",
    "        optimizer: torch.optim.SGD,\n",
    "        criterion: nn.CTCLoss,\n",
    "        label_converter: LabelConverter,\n",
    "        epochs: int = 50,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.label_converter = label_converter\n",
    "        self.epochs = epochs\n",
    "        self.device = config.DEVICE\n",
    "\n",
    "    def calculate_loss(self, output: torch.Tensor, target: Tuple):\n",
    "        c, n = output.size(0), output.size(1)\n",
    "        output_lengths = torch.full(size=(n,), fill_value=c, dtype=torch.int32)\n",
    "        target_encoded, target_lengths = self.label_converter.encode(target)\n",
    "        loss = self.criterion(output, target_encoded, output_lengths, target_lengths)\n",
    "        return loss\n",
    "\n",
    "    def fit(\n",
    "        self, train_loader: DataLoader, test_loader: DataLoader\n",
    "    ) -> Tuple[Dict, List[float], List[float]]:\n",
    "        train_history_loss = []\n",
    "        test_history_loss = []\n",
    "        for epoch in tqdm(range(self.epochs), total=self.epochs):\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            self.model.train()\n",
    "            for image, target, _ in train_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                image = image.to(device=self.device)\n",
    "                output = self.model(image)\n",
    "        \n",
    "                train_loss = self.calculate_loss(output, target)\n",
    "                if np.isnan(train_loss.detach().cpu().numpy()):\n",
    "                    continue\n",
    "                train_history_loss.append(train_loss.detach().cpu().numpy())\n",
    "                train_loss.backward()\n",
    "\n",
    "                nn.utils.clip_grad_norm_(self.model.parameters(), 1)\n",
    "\n",
    "                self.optimizer.step()\n",
    "\n",
    "            results, test_history_loss = self.evaluate(test_loader, test_history_loss)\n",
    "            plot_loss(epoch + 1, train_history_loss, test_history_loss)\n",
    "\n",
    "            saving = {\n",
    "                'state_dict': self.model.state_dict(),\n",
    "                'optimizer': self.optimizer.state_dict(),\n",
    "                'char2idx': label_converter.char2idx,\n",
    "                'idx2char': label_converter.idx2char,\n",
    "                }\n",
    "            torch.save(saving, 'model.pth')\n",
    "            print(results)\n",
    "\n",
    "        return results, train_history_loss, test_history_loss\n",
    "\n",
    "    def evaluate(\n",
    "        self, test_loader: DataLoader, test_history_loss: List[float]\n",
    "    ) -> Tuple[Dict, List[float]]:\n",
    "        outputs = {\"predict\": [], \"target\": [], \"image\": []}\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for image, target, path_image in test_loader:\n",
    "                image = image.to(device=self.device)\n",
    "                output = self.model(image)\n",
    "\n",
    "                test_loss = self.calculate_loss(output, target)\n",
    "                if np.isnan(test_loss.detach().cpu().numpy()):\n",
    "                    continue\n",
    "                test_history_loss.append(test_loss.detach().cpu().numpy())\n",
    "\n",
    "                outputs[\"predict\"].append(output.detach().cpu())\n",
    "                outputs[\"target\"].append(target)\n",
    "                outputs[\"image\"].append(path_image)\n",
    "\n",
    "        return outputs, test_history_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = Recognition(model, optimizer, criterion, label_converter, 30)\n",
    "results, train_loss, test_loss = engine.fit(train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = []\n",
    "for predicts, targets, images in zip(\n",
    "    results[\"predict\"], results[\"target\"], results[\"image\"]\n",
    "):\n",
    "    for idx in range(len(images)):\n",
    "        output = label_converter.decode(predicts[:, idx, :].unsqueeze(1))\n",
    "        df_results.append([output, targets[idx], images[idx]])\n",
    "df_results = pd.DataFrame(df_results, columns=[\"predict\", \"target\", \"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCR_Dataset_Test(Dataset):\n",
    "    def __init__(self, path_images: str):\n",
    "        self.path_images = path_images\n",
    "        self.images = []\n",
    "        files = os.listdir(path_images)\n",
    "\n",
    "        for image in files:\n",
    "            self.images.append(os.path.join(path_images, image))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path_img = self.images[index]\n",
    "        image = Image.open(path_img)\n",
    "\n",
    "        transform = transforms.Compose(\n",
    "                [\n",
    "                    lambda image: image.convert(\"RGB\"),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize((config.INPUT_SIZE[0], config.INPUT_SIZE[1])),\n",
    "                    transforms.Normalize(config.IMAGENET_MEAN, config.IMAGENET_STD)\n",
    "                ]\n",
    "        )\n",
    "        img = transform(image)\n",
    "\n",
    "        return img, path_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = OCR_Dataset_Test(config.TEST_IMAGES)\n",
    "loader = DataLoader(data, batch_size=config.BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model.pth\", map_location=torch.device(config.DEVICE))\n",
    "model = OCR_Model().to(device=config.DEVICE)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for image, path_image in loader:\n",
    "        image = image.to(device=config.DEVICE)\n",
    "        output = model(image)\n",
    "        output = output.detach().cpu()\n",
    "\n",
    "        for idx in range(len(path_image)):\n",
    "            df_results.append([path_image[idx], label_converter.decode(output[:, idx, :].unsqueeze(1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(df_results, columns=[\"Path\", \"Predicted\"])\n",
    "df_results[\"Id\"] = df_results[\"Path\"].apply(lambda x: x.split(\"\\\\\")[-1])\n",
    "df_results[\"RN\"] = df_results[\"Id\"].apply(lambda x: int(x.split(\".jpg\")[0]))\n",
    "df_results.sort_values(\"RN\", inplace=True)\n",
    "df_results.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = df_results[[\"Predicted\"]]\n",
    "df_results.drop([\"Path\", \"RN\", \"Predicted\"], axis=1, inplace=True)\n",
    "df_results = pd.concat([df_results, predicts], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"result/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
